\documentclass[11pt,twoside=off,numbers=noenddot]{scrbook}

\input{preamble}
\input{macros}

\title{Notes on Logic in Computer Science}
\author{Richard Willie}

\begin{document}

\maketitle

\tableofcontents

\newpage

\chapter{First-Order and Monadic Second-Order Logic on Words}
In this chapter, we look into the expressive power of first-order and monadic second-order logic when the class of structures is restricted to words, i.e. \emph{word structures}.

\section{Recap: first-order logic}
\todo{Write the rest of this.}

\subsection{Syntax and semantics}
\todo{Write the rest of this.}

\section{First-order logic on words}
\todo{Write the rest of this.}

\subsection{Syntax and semantics}
\todo{Write the rest of this.}

\section{Expressive power of $\FO(\Sigma)$}
\todo{Write the rest of this.}

\section{Recap: second-order logic}
Second-order logic is an extension of first-order logic. Recall that one of the main features of first-order logic over propositional logic, was the ability to quantify over elements that are in the universe of the structure. Second-order logic not only allows one to quantify over elements of the universe, but in addition, also allows quantifying relations over the universe.

To help illustrate the distinction between first-order and second-order logic, it's helpful to consider an example from number theory. Here, the objects of our study are the natural numbers $0, 1, 2, \dots$ and their arithmetic. Using first-order logic, we can make statements about these numbers through atomic expressions such as $x = y$, $x + y = z$, and $x \times y = z$. These expressions are combined with logical connectives like $\wedge$, $\neg$, $\vee$, and $\rightarrow$, as well as quantifiers $\forall x$ and $\exists x$, where the variables $x, y, z, \dots$ range over the natural numbers.

In second-order logic, we can express even more complex ideas. In addition to variables like $x, y, z, \dots$ that represent numbers, second-order logic introduces variables $X, Y, Z, \dots$ that represent properties or relations between numbers. For these variables, we also have quantifiers $\forall X$ and $\exists X$. This means we can now quantify over properties or relations, not just individual elements. Moreover, in addition to first-order atomic expressions, we have new atomic expressions of the form $X(y_1, \dots, y_n)$.

\subsection{Syntax and semantics}
Like first-order logic, second-order logic is defined over a \emph{signature}.

\begin{definition}[Signatures in second-order logic]
  A \emph{signature} is $\tau = \set{\consts, \funcs, \rels}$, where
  \begin{enumerate}
    \item $\consts = \set{c_1, c_2, \dots}$ is a set of constant symbols,
    \item $\funcs = \set{f_1^1, f_2^1, \dots, f_1^2, f_2^2, \dots, f_j^k, \dots}$ is a set of function symbols, where the superscript indicates the arity of the function, and
    \item $\rels = \set{R_1^1, R_2^1, \dots, R_1^2, R_2^2, \dots, R_j^k, \dots}$ is a set of relation symbols, where the superscript indicates the arity of the relation.
  \end{enumerate}
\end{definition}

Second-order logic has several kinds of \emph{variables}. It has \emph{individual variables} denoted by lower case letters $x, y, z, \dots$ possibly with subscripts. It has \emph{property} and \emph{relation variables} denoted by uppercase letters $X, Y, X, \dots$ possibly with subscripts. Finally, it has \emph{function variables} denoted by uppercase letters $F, G, H, \dots$ possibly with subscripts. Each relation and function variable has an arity, which is a positive natural number. We identify property variables with 1-ary relation variables.

\begin{remark}
  It is noteworthy that although we have property variables, we do not have variables for properties of properties. Such variables would be part of the formalism of third-order logic.
\end{remark}

Formulas in second-order logic over signature $\tau = (\consts, \rels)$ are sequences of symbols, where each symbol is one of the following.
\begin{enumerate}
  \item The symbol $\bot$, called \emph{false}.
  \item The symbol $=$, called \emph{equality}.
  \item An element of the infinite set $\vars_1 = \set{x_1, x_2, \dots}$ of \emph{variables}.
  \item An element of the infinite set $\vars_2 = \set{X_1^1, X_2^1, \dots, X_1^2, X_2^2, \dots, X_j^k, \dots}$ of \emph{relational variables}, where the superscript indicates the arity of the variable.
  \item Constant symbols and relation symbols in $\tau$.
  \item The symbol $\neg$, called \emph{negation}.
  \item The symbol $\vee$, called \emph{disjunction}.
  \item The symbol $\exists$, called the \emph{existential quantifier}.
  \item The symbols $($ and $)$, called \emph{parentheses}.
\end{enumerate}

\begin{remark}
  For simplicity, we restrict the signature $\tau$ in the definition above to include only constant symbols and relation symbols. In other words, we exclude function symbols and function variables as, after all, functions are just special kinds of relations. In addition, we also omit certain logical symbols, such as $\wedge$ (conjunction), $\rightarrow$ (implication), and the universal quantifier $\forall$.
\end{remark}

\begin{abuse}
  We will, however, use the logical symbols $\wedge$, $\rightarrow$, and $\forall$ when it's convenient. We appeal to the fact that these symbols can be defined in terms of the others.
\end{abuse}

As always, not all such sequences are formulas; only \emph{well-formed} are formulas in the logic. In order to define well-formed formulas, we first define the set of \emph{terms}.

\begin{definition}[Terms in second-order logic]
  A \emph{term} $t$ over signature $\tau = (\consts, \rels)$ is either
  \begin{enumerate}
    \item a constant symbol $c \in \consts$, or
    \item a variable $x \in \vars_1$.
  \end{enumerate}
\end{definition}

Having defined terms, we can use them to define well-formed formulas.

\begin{definition}[Well-formed second-order formulas]
  A \emph{well-formed formula (wff)} over signature $\tau = (\consts, \rels)$ is inductively defined as follows.
  \begin{enumerate}
    \item $\bot$ is a wff.
    \item If $t_1$ and $t_2$ are terms, then $t_1 = t_2$ is a wff.
    \item If $t_1, \dots, t_k$ are terms and $R^k$ is a relational symbol in $\rels$, then $R^k(t_1, \dots, t_k)$ is a wff.
    \item If $t_1, \dots, t_k$ are terms and $X^k$ is a relational variable in $\vars_2$, then $X^k(t_1, \dots, t_k)$ is a wff.
    \item If $\phi$ is a wff, then $(\neg \phi)$ is a wff.
    \item If $\phi_1$ and $\phi_2$ are wffs, then $(\phi_1 \vee \phi_2)$ are wffs.
    \item If $\phi$ is a wff and $x$ is a variable in $\vars_1$, then $(\exists x \phi)$ is a wff.
    \item If $\phi$ is a wff and $X^k$ is a relational variable in $\vars_2$, then $(\exists X^k \phi)$ is a wff.
  \end{enumerate}
\end{definition}

More succinctly, we could capture the above definitions of terms and well-formed formulas by the following BNF grammar,
\begin{align*}
  t & ::= c \mid x \\
  \phi & ::= \bot \mid t = t \mid R(t, \dots, t) \mid X(t, \dots, t) \mid (\neg \phi) \mid (\phi \vee \phi) \mid (\exists x \phi) \mid (\exists X \phi)
\end{align*}
where $c$ is a constant symbol, $x$ is a variable, and $X$ is a relational variable.

\emph{Atomic formulas} are well-formed formulas that do not have any logical operators, i.e. either of the form
\begin{enumerate}
  \item $\bot$, or
  \item $t_1 = t_2$ where $t_1$ and $t_2$ are terms, or
  \item $R^k(t_1, \dots, t_k)$ where $R^k$ is a $k$-ary relational symbol and $t_1, \dots, t_k$ are terms, or
  \item $X^k(t_1, \dots, t_k)$ where $X^k$ is a $k$-ary relational variable and $t_1, \dots, t_k$ are terms.
\end{enumerate}

Finally, a \emph{literal} is a formula that is either atomic or the negation of an atomic formula.

\begin{remark}
  It is interesting to note that in second-order logic we can actually define the identity $t_1 = t_2$ as $\forall X (X(t_1) \leftrightarrow X(t_2))$ and prove the familiar axioms of identity from properties of the implication.
\end{remark}

To define the semantics of second-order logic, we first need to establish the \emph{metalanguage} we will use. This requirement has nothing to do with second-order logic but is rather a general feature of semantics due to Tarski \cite{tarski1956concept}. The most common choice for a metalanguage is \emph{set theory}. We thus give a set-theoretical interpretation of second-order logic, where ``properties'' are understood as sets within a domain, which itself is a set. This set-theoretical interpretation is standard and highlights the key features of second-order logic.

\begin{remark}
  It's important to note, however, that not all properties can be represented as sets—for example, the property of being identical to oneself. But when we treat the domain of individual variables as a set, we can meaningfully interpret the properties of individuals within that domain as sets. If we need to interpret second-order logic in a domain too large to be a set, we can instead use the set-theoretical concept of a \emph{class}. (For a discussion on the set/class distinction in the context of second-order logic, see Shapiro \cite{shapiro1991foundations}.)
\end{remark}

Like in the case of first-order logic, the semantics of formulas in second-order logic are defined with respect to a \emph{structure} (or equivalently, a \emph{model}). Recall that a structure is a \emph{universe} along with an \emph{interpretation} of the constant symbols and relation symbols in the signature. To define whether a formula holds in a structure, we also need an \emph{assignment}, which interprets free variables. For first-order logic, an assignment was simply a mapping of variables to elements in the universe of the structure. For second-order logic, however, the presence of relational variables, means that an assignment must also give an interpretation of these variables as relations (of the appropriate arity) over the structure. These are formally defined as follows.

\begin{definition}[Structures in second-order logic]
  A \emph{$\tau$-structure} $\struct$ is a tuple, $(A, \set{c^\struct}_{c \in \tau}, \set{R^\struct}_{R \in \tau})$ where
  \begin{enumerate}
    \item $A$ is a non-empty set called the \emph{universe} (or \emph{domain}) of the structure,
    \item for each constant symbol $c \in \tau$, $c^\struct \in U$ is its interpretation, and
    \item for each $k$-ary relational symbol $R \in \tau$, $R^\struct \subseteq U^k$ is its interpretation.
  \end{enumerate}
\end{definition}

The structure $\struct$ is said to be \emph{finite} if the universe $A$ is finite. The universe of a structure $\struct$ will be denoted by $u(\struct)$.

\begin{definition}[Assignments in second-order logic]
  \deflabel{assignments-in-sol}
  Given a $\tau$-structure $\struct$, an \emph{assignment} $\alpha$ over $\struct$ is a pair of functions $(\alpha_1, \alpha_2)$ defined as follows.
  \begin{enumerate}
    \item $\alpha_1 : \vars_1 \to u(\struct)$ assigns each individual variable $x$ to a variable $\alpha_1(x) \in u(\struct)$.
    \item $\alpha_2 : \vars_2 \to \cup_k (u(A))^k$ assigns each $k$-ary relational variable $X^k$ to a relation $\alpha_2(X^k) \subseteq (u(A))^k$.
  \end{enumerate}
\end{definition}

\begin{abuse}
  From here on, we will extend $\alpha_1$ to apply to any term, not just variables. If the term $t$ is a constant symbol $c$, we take $\alpha_1(t)$ to be $c^\struct$. For any variable $x$, we will apply $\alpha_1$ as per \defref{assignments-in-sol}.
\end{abuse}

We are now ready to define the semantics of a second-order formula in a structure under an assignment.

\begin{definition}[Satisfaction of second-order formulas]
  The relation $\struct, \alpha \models \phi$ is inductively defined as follows.
  \begin{enumerate}
    \item $\struct, \alpha \not\models \bot$ for all $\struct$ and $\alpha$.
    \item $\struct, \alpha \models t_1 = t_2$ iff $\alpha_1(t_1) = \alpha_1(t_2)$.
    \item $\struct, \alpha \models R(t_1, \dots, t_k)$ iff $(\alpha_1(t_1), \dots, \alpha_k(t_k)) \in R^\struct$.
    \item $\struct, \alpha \models X^k(t_1, \dots, t_k)$ iff $(\alpha_1(t_1), \dots, \alpha_k(t_k)) \in \alpha_2(X^k)$.
    \item $\struct, \alpha \models (\neg \phi)$ iff $\struct, \alpha \not\models \phi$.
    \item $\struct, \alpha \models (\phi_1 \vee \phi_2)$ iff $\struct, \alpha \models \phi_1$ or $\struct, \alpha \models \phi_2$.
    \item $\struct, \alpha \models (\exists x \phi)$ iff there exists $a \in u(\struct)$ such that $\struct, \alpha[x \mapsto a] \models \phi$.
    \item $\struct, \alpha \models (\exists X^k \phi)$ iff there exists $S \in (u(\struct))^k$ such that $\struct, \alpha[X^k \mapsto S] \models \phi$.
  \end{enumerate}
\end{definition}

The definition above suggests that the assignment of values to variables (individual and relational) only matters for the \emph{free} variables, i.e. those that are not quantified. We extend the definition of free and bound occurrences to relational variable as well.

\begin{definition}[Free and bound variables in second-order logic]
  In well-formed formulas $(\exists x \phi_1)$ and $(\exists X^k \phi_2)$, $\phi_1$ and $\phi_2$ are said to be in scope of the quantifiers $\exists x$ and $\exists X^k$, respectively. Every occurrence of $x$ and $X^k$ in $(\exists x \phi)$ and $(\exists X^k \phi)$, respectively, are said to be \emph{bound}. Any occurrences of variables (individual and relational) are said to be \emph{free}.
\end{definition}

When comparing different variable assignments and their effect on a given formula $\phi$, those variables that do not occur in the formula or are not free variables in the formula should not affect the fact that a given structure $\struct$ logically implies the formula or not. We state this intuitive result in the following.

\begin{lemma}[The relevance lemma for second-order logic]
  For a formula $\phi$ and assignments $\alpha$ and $\beta$ that agree on all the free variables and free relational variables of $\phi$, we have $\struct, \alpha \models \phi$ iff $\struct, \beta \models \phi$.
\end{lemma}

\emph{Sentences} are formulas with no free variables or relational variables. Thanks to the relevance lemma, this means that for sentences, the assignment does not determine its satisfaction.

\begin{proposition}
  For a sentence $\phi$ and any two assignments $\alpha$ and $\beta$, we have $\struct, \alpha \models \phi$ iff $\struct, \beta \models \phi$. Therefore, we write $\struct \models \phi$ if for any assignment $\alpha$, $\struct, \alpha \models \phi$.
\end{proposition}

Satisfiability and validity of second-order formulas are defined in the same way as for first-order logic. In other words, $\phi$ is \emph{satisfiable} if there is a structure $\struct$ and assignment $\alpha$ such that $\struct, \alpha \models \phi$; and $\phi$ is \emph{valid} if for every structure $\struct$ and assignment $\alpha$, $\struct, \alpha \models \phi$.

\subsection{Monadic second-order logic}
\emph{Monadic second-order logic (MSO)} is an important fragment of second-order logic. While first-order logic can be seen as the fragment that does not allow relational variables, MSO is the fragment where all relational variables are \emph{monadic}, i.e. of arity 1. Thus, in MSO one can only quantify over sets, as opposed to more general relations.

\begin{abuse}
  Since all relational variables are monadic, from now on we will drop the superscript that indicates the variables arity.
\end{abuse}

\begin{abuse}
  Sometimes, we may also skip parentheses for convenience. For instance, instead of writing $R(x)$, we will just write $R x$.
\end{abuse}

\begin{example}
  Consider the signature of graphs $\tau_G = \set{E}$ which consists of a single binary relation which denotes the edge relation in the graph. We give the following sentence that expresses the fact that the edge relation $E$ encodes a graph that is 3-colorable.
  \begin{align*}
    \exists X_1 \exists X_2 \exists X_3 ( & (\forall x (X_1 x \vee X_2 x \vee X_3 x)) \wedge \\
    & (\forall x \forall y (E x y \rightarrow (\neg (X_1 x \wedge X_1 y) \wedge \neg (X_2 x \wedge X_2 y) \wedge \neg (X_3 x \wedge X_3 y)))))
  \end{align*}
  The sentence above is monadic.
\end{example}

\section{Monadic second-order logic on words}
In this section, we will study MSO on a restricted class of structures, specifically, \emph{word structures}. Before introducing MSO on words more formally, let us become familiar with it at an intuitive level. We start by fixing an alphabet $\Sigma = \set{a, b}$. MSO on words has three types of atomic formulas:
\begin{enumerate}
  \item Formulas of the form $Q_a(x)$ or $Q_b(x)$, where $x$ is a variable ranging over the positions of the word. The intended meaning of $Q_a(x)$ if ``the letter at position $x$ is $a$,'' and the meaning of $Q_b(x)$ is analogous. For instance, the predicate ``all letters of the words are $a$s'' is expressed by the formula $\forall x \ Q_a(x)$. The language of all words satisfying the formula, called just the language of the formula is $\lang(a^\ast)$.
  \item Formulas of the form $x < y$, where $x$ and $y$ range over the positions of the word. The intended meaning is ``position $x$ is smaller than (i.e. lies to the left of) position y.'' For example, the predicate ``if some letter is in $a$, then all subsequent letters are also in $a$s'' is expressed by the formula
    \[ \forall x \forall y ((Q_a(x) \wedge x < y) \rightarrow Q_a(y)). \]
    The language of the formula is $\lang(b^\ast a^\ast)$. Notice, however, that this is so because $\Sigma = \set{a, b}$. If $\Sigma = \set{a, b, c}$, then the language of the formula is $\lang((b + c)^\ast a^\ast)$.
  \item Formulas of the form $S(x, y)$ where $x$ and $y$ range over the positions of the word. The intended meaning is ``$y$ is the next position after $x$'' or ``position $x$ plus one is position $y$.'' For example, the predicate ``the next letter after $a$ is $b$, and the next letter after $b$ is $a$'' is expressed by the formula
    \[ \forall x \forall y (S x y \rightarrow ((Q_a(x) \wedge Q_b(y)) \vee (Q_b(x) \wedge Q_a(y)))). \]
    The language of the formula is $\lang((ab)^\ast + (ba)^\ast)$.
\end{enumerate}

\subsection{Syntax and semantics}
Let's start by defining the signature of MSO on words.

\begin{definition}[The signature of $\MSO(\Sigma)$]
  Given an alphabet $\Sigma$, the signature of $\MSO(\Sigma)$ is fixed to be $\tau_W = (\set{Q_a}_{a \in \Sigma}, <, S)$ where $Q_a$ is a unary relation symbol for every $a$ in the alphabet $\Sigma$, and $<$, $S$ are binary relation symbols.
\end{definition}

Now, we formally define the syntax of MSO on words, using BNF grammar.

\begin{definition}[The syntax of $\MSO(\Sigma)$]
  The set $\MSO(\Sigma)$ of monadic second-order formulas over an alphabet $\Sigma$ is the set of expressions generated by the following grammar,
  \[ \phi ::= Q_a(x) \mid x < y \mid S(x, y) \mid (\neg \phi) \mid (\phi \vee \phi) \mid (\exists x \phi) \mid (\exists X \phi) \]
  where $a$ is in the alphabet $\Sigma$, $x, y$ are variables, and $X$ is a relational variable.
\end{definition}

Finally, a \emph{word structure} is defined as follows. Its universe consists of the positions in the word, and the relations $Q_a$, $<$, and $S$ are interpreted in the ``standard'' way.

\begin{definition}[Word structures]
  Given an alphabet $\Sigma$ and a word $w \in \Sigma^\ast$, let $n$ be the length of $w$. The structure of $w$ is defined by
  \begin{align*}
    \wstruct = ( & \set{1, 2, \dots, n}, \\
      & < = \set{(1, 2), (1, 3), \dots, (1, n), (2, 3), \dots, (2, n), \dots, (n - 1, n)}, \\
      & S = \set{(1, 2), (2, 3), (3, 4), \dots, (n - 1, n)}, \\
    & \set{Q_a = \set{x \mid \text{the letter at position $x$ is $a$}}}_{a \in \Sigma}).
  \end{align*}
\end{definition}

\todo{Write some examples to round out this subsection.}

\section{The Büchi-Elgot-Trakhtenbrot theorem}
The main result we will establish in this section is that the set of words definable in MSO exactly corresponds to the set of regular languages.

\begin{abuse}
  Note that there is a one-to-one correspondence between elements of $\Sigma^\ast$ and word structures over $\Sigma$. Thus, from now on, we will use $w$ interchangeably to refer both to an element of $\Sigma^\ast$ and to the corresponding word structure.
\end{abuse}

\begin{definition}[MSO-definable languages]
  A language $A$ (or, equivalently, a set of words or word structures) over an alphabet $\Sigma$ is said to be \emph{definable} in MSO if there exists an MSO sentence $\phi$ over the signature $\tau_W = (\set{Q_a}_{a \in \Sigma}, <, S)$ such that $A = \set{w \mid w \models \phi}$.
\end{definition}

\begin{theorem}[The Büchi-Elgot-Trakhtenbrot theorem]
  A language $A$ is definable in MSO if and only if $A$ is regular.
\end{theorem}

\begin{remark}
  The Büchi-Elgot-Trakhtenbrot theorem is of fundamental importance in automata theory because it gives a logical characterization of the regular languages. It was proven independently by Büchi \cite{buchi1960weak}, Elgot \cite{elgot1961decision}, and Trakhtenbrot \cite{trakhtenbrot1962finite}.
\end{remark}

\subsection{Regular languages are expressible in $\MSO(\Sigma)$}
\todo{Write the rest of this.}

\subsection{Languages expressible in $\MSO(\Sigma)$ are regular}
\todo{Write the rest of this.}

\printbibliography[nottype=image]

\end{document}
